# 🧠 赛题解析与统一问题抽象  
**Industrial Multi-Scenario Forecasting — Problem Understanding**

本仓库对应比赛为：

> **第八届 数境杯 · 大模型工业多重场景挑战赛**
> 目标：使用一个通用模型完成三个完全不同的时间序列预测任务

---

## 1. 赛题目标：从“多模型”走向“通用模型”

### 传统范式
> 一个任务 → 一个模型 → 一个 pipeline

缺点：
❌ 无法复用  
❌ 每个任务重新调参  
❌ 扩展到新场景成本极高  
❌ 模型对工业落地不友好

### 本赛题范式要求
> 一个模型 → 多个任务 → 多种数据分布

目标是实现：
✔ 跨领域泛化  
✔ 统一数据接口  
✔ 无需重新设计模型结构  
✔ 具备可解释与工业可复现性  

换言之，比赛考察的不是 “你能不能调出一个高分模型”  
而是 **你能不能设计一个可扩展、可复现、可推广的系统**

---
## 2. 赛题解析与多场景差异分析

本次比赛要求选手使用 **同一个模型框架** 解决三个工业场景的预测任务。这三个场景不是简单变量替换，而是涵盖了**时间尺度、数据分布、稀疏程度、场景性质完全不同**的预测问题。

---

### 2.1 三个子赛题概述与核心挑战对比

| 赛题 | 场景 | 预测目标 | 时间粒度 | 特点与难点 |
|------|------|----------|-----------|-------------|
| Task 1 | 风电场 | 未来 10 分钟风速/风向（每 30 秒一次，共 20 步） | 30秒 | 高频序列、连续采样、强波动、机组差异大、数据规模大 |
| Task 2 | 水库入库 | 未来 7天入库流量（每 3 小时一次，共 56 步） | 3小时 | 存在物理滞后、降雨输入、气象驱动、长序列依赖、间断时间 |
| Task 3 | 离散制造 | 未来 1-3 个月物料需求预测（每月一次） | 月级 | 极端稀疏、nan密集、冷启动、需求不规律、数据量极小 |

---

### 2.2 为什么它们难以统一？
从时间序列的角度来看，本题最大的难点不是建模，而是 —— **数据结构完全不同**。

#### 📌 1. 时间尺度不一致
- Task1: 秒级（30s）
- Task2: 小时级（3h）
- Task3: 月级

这意味着：
> 不能简单共享采样窗口、序列长度、输入结构  
> 相当于三种不同的“时间世界”

#### 📌 2. 数据规模差异巨大
| 任务 | 样本规模 |
|------|---------|
| Task1 | 25台×2场×2年×30s → 数千万行 |
| Task2 | 4年×(每3小时) → ~12000行 |
| Task3 | 3年×(每月) → 36行（部分物料甚至不足10条） |

模型必须同时处理：
✔ big-data case (Task 1)  
✔ small-data case (Task 3)  
→ 这是大多数 deep learning / transformer 直接崩溃的场景

#### 📌 3. 数据稀疏性差异极大
Task1：连续传感器数据，无缺失（或可插值）  
Task2：存在间断、非均匀采样、缺失值  
Task3：天生稀疏，缺失是数据本身属性（不是异常）

> **这不仅仅是缺失值问题，而是数据生成机制不同**

#### 📌 4. 预测任务本质不同
| 任务 | 类型 |
|------|------|
| Task1 | 超短期预测（nowcasting） |
| Task2 | 水文时间序列（物理驱动） |
| Task3 | 离散业务时间序列（业务驱动） |

因此，三者不是“多任务”，而是三种完全不同的时间序列预测类型：

- **任务1像天气预报**
- **任务2像河流流域水量模型**
- **任务3更像销售预测问题**

---

### 2.3 总结：为什么这是一道真正的“通用建模”难题？

本赛题本质考察的是 ——  
✔ 对时序问题本质的抽象能力  
✔ 设计统一建模方法的理论基础  
✔ 面对三种极端不同数据集时，如何做到 **共享而不简单拼接**

因此，
**最难的不是模型怎么训练，而是如何构建一个合理的统一范式**

---

## 3. 比赛规则核心理解与影响

### ✔ 必须为“通用模型”
不是：
❌ 分别训练3个模型  
❌ 3个Notebook拼一起  
❌ 3个特征工程 pipeline

而应该是：
✔ 统一数据格式  
✔ 统一输入输出结构  
✔ 统一建模框架  
✔ 可以通用地支持任意任务

**只要是同一个模型框架 + 通用范式 = 合格**

甚至只要：
```

统一数据处理 + XGBoost

```
也完全符合规则（事实上，绝大多数队伍是这么做的）

---

### ✔ 不要求参数共享 / 多任务训练
这说明评委不在乎你是不是多任务 joint training  
而在乎你是否理解“通用性”的设计

---

## 4. 问题抽象：如何把三个任务统一成一个数学形式？

虽然看起来不同，但它们共享一个核心结构：

> 输入：过去 L 步的时间序列  
> 输出：未来 H 步预测值

统一为自回归滑动窗口格式：

<img width="700px" src="https://latex.codecogs.com/svg.image?X\in\mathbb{R}^{L\times&space;d},\quad&space;y\in\mathbb{R}^{H}">

只需修改：
- L（历史长度）
- H（预测长度）
- d（特征维度）
即可支持所有场景

> 核心思想：**用数据范式统一，而不是用模型硬套**

---
## 5. 本方案思路
我们的项目挑战性在于，需要用一个通用模型同时解决三个横跨不同行业的工业级子赛题：高频的风电场风况预测、中长期的水电站入库流量预测，以及高度稀疏的离散制造物料需求预测。我们的核心贡献是，在资源极其有限的情况下，设计了一个高效且高度通用的解决方案。
### 5.1 赛题分析
首先进行赛题分析，我们通过简单的预处理之后可视化了一些赛题数据。发现虽然这三个场景各不相同，但它们的时序数据都呈现出显著的共性特征：强噪声、多源异构、高波动性和非平稳性。面对这些挑战，我们迅速确定 ARIMA、Prophet 等传统统计模型不再适用。它们的核心缺陷在于：线性假设无法捕捉风电突变和水文径流的复杂非线性；建模维度受限，难以高效融合多个气象和业务特征；同时，对于物料需求中高度的稀疏性和间歇性也束手无策。因此，我们的起点是：必须采用深度学习算法来捕捉数据中复杂的非线性依赖关系。

在确定使用深度学习后，我们面临两个关键挑战：首先是场景多样性： 如何用一个模型统一处理 30 秒分辨率的超短期预测和 7 日的中长期预测？其次是资源约束（关键）： 本项目为个人独立参赛，我们仅能使用 Kaggle Notebook 和 Google Colab 等免费计算资源。这意味着我们无法进行大规模的分布式训练，无法长期占用 GPU，且模型的推理速度必须极快。因此，我们的目标非常明确：设计一个轻量级、高复现性，且在时序本质上具备通用性的预测框架，它必须比主流的 Transformer 更加高效。

竞赛明确鼓励使用通用大模型的思路进行建模。为了响应这一要求，我们首先尝试了如 TIMER-XL 这类长文本 Transformer 基线。然而，实证结果表明，这类模型在我们的工业级数据集上存在两个主要问题：首先是初始效果不佳： 原始的 Transformer 模型在我们的强噪声、小样本数据上，泛化能力并不理想。其次是资源与时间瓶颈： 无论是直接使用基线还是尝试指令微调，其高昂的训练成本和长时间的 GPU 占用，都远远超出了我们免费计算资源所能承受的范围。因此，我们决定进行学术转向，质疑这一路线的合理性。
### 5.2 赛题思路
我们放弃了 Transformer/LLM 的路径，是基于扎实的学术批判。我们引用了 **Christoph Bergmeir 教授在 NeurIPS 2024 上的主题演讲《Foundational limitations of foundational forecasting models》**中的核心观点：‘全局模型理论不适用于基础预测模型。’ Bergmeir 教授指出，目前许多时序 Transformer 模型缺乏严格的评估基准，其在特定数据集上的优势并不具备通用性。这一观点与我们的核心哲学不谋而合：任何时间序列的通用本质，在于其可分解的‘趋势’（Trend）和‘周期性’（Seasonality），而非复杂的非线性依赖。盲目堆砌大模型规模，并不能解决时序预测的核心挑战。”

“基于对时序本质的理解和对大模型的审慎态度，我们最终选择了AAAI23年的论文 **DLinear（LTSF-Linear、Zeng, A., Chen, M., Zhang, L., & Xu, Q. (2022). Are Transformers Effective for Time Series Forecasting? arXiv preprint arXiv:2205.13504v3.）**作为统一框架，并将其作为我们创新性的体现。我们引用 2023 年AAAI的论文，该研究证明了在有效分解序列后，一个简单的单层线性模型在长期预测基准上表现显著优于所有复杂的 Transformer 模型。这背后的核心原因论文作者表示是：Transformer 的核心机制 —— 自注意力是 “置换不变的”（对序列顺序不敏感），尽管通过位置编码等方式保留部分顺序信息，但其本质仍会导致时间信息丢失；而时间序列预测的核心是捕捉连续数据点的时间关系，顺序至关重要。此外，现有 Transformer-based LTSF 方法的性能提升可能源于其采用的 “直接多步（DMS）预测策略”，而非模型本身，因为它们对比的基线多是存在误差累积的 “迭代多步（IMS）预测”。DLinear 的优势在于：它将计算资源聚焦于高效的分解，而非复杂的非线性捕捉。这不仅解决了我们的算力限制问题，同时也提供了一个理论上更稳健、更符合时序特性的解决方案。

---

# ✨ 6. 技术解题路线（核心技术方案）

本节是本项目最核心的部分，将说明：

1. 我们如何通过统一范式处理三种极端不同的任务
2. 为什么选择 DLinear 而不是 Transformer
3. 如何将 Prophet 思想神经网络化进行增强
4. 针对三类赛题的自适应策略（重点）
5. 全部设计如何保证可扩展、可解释、可复现

---

## 6.1 🎯 总体策略对照表（核心思想一图总结）

| 关键挑战          | 常规失败方案            | 我们的策略                 |
| ------------- | ----------------- | --------------------- |
| 数据跨度差异极大      | 3 套独立模型           | 📌统一滑动窗口范式            |
| 小样本 + 缺失 + 噪声 | 手工填补 / 不处理        | 📌序列分解 + 插值策略         |
| 资源极度受限        | Transformer / LLM | 📌DLinear + CPU训练兼容   |
| 工业可解释性        | 黑盒深度模型            | 📌趋势-季节分解，高可解释        |
| 复现难           | Notebook + 复杂依赖   | 📌Docker 化，单脚本运行      |
| 通用性考核         | “套3个模型”假通用        | 📌同架构、同 pipeline、配置驱动 |

---

## 6.2 🧠 为什么选择 DLinear？（设计哲学）

DLinear 的核心思想：

> 用 **时间序列分解（Trend + Seasonal） + 线性层** 替代 Attention

它的结构像这样：

```
x ---> decomposition ---> [trend] ---> linear --> y_trend
                \-----> [season] --> linear --> y_season
y = y_trend + y_season
```

### 关键优势

✔ O(T) 复杂度，比 Transformer 更轻
✔ 支持小数据，不容易过拟合
✔ CPU/GPU 都能跑，Colab免费资源可复现
✔ 原生可解释，可视化趋势 & 周期成分
✔ 多赛题统一架构仍能保持性能

---

## 6.3 📌 DLinear ≈ Neural Prophet：我们做了进一步增强

原始 DLinear：

```
y = Linear(Trend(x)) + Linear(Season(x))
```

而 Prophet 的分解思想是：

```
y = Trend + Season + Holiday + Residual
```

我们将 Prophet 的思想 **神经网络化**，提出改进版本：

### 🔬 神经分解模型（我们的方法）

```
y = LT(Trend(x)) + LS(Season(x)) + LH(Holiday(x)) + LR(Residual(x))
```

其中：

* `LT` 捕捉趋势缓慢变化
* `LS` 捕捉周期波动（季节性）
* `LH` 注入节假日/业务事件（外生变量）
* `LR` 捕捉残差非线性成分

### 🌟 收益

| 指标    | 原始 DLinear | 我们改进版 |
| ----- | ---------- | ----- |
| 可解释性  | ✔          | ✔✔✔   |
| 小样本表现 | 中          | 高     |
| 长期预测  | 稳定         | 更稳    |
| 工业可用性 | ✔          | ✔✔    |

---

## 6.4 📍 三场景适配策略

### Task1：风电风况预测（秒级高频 / 数据量极大）

📌 特点：

* 30s 分辨率
* 巨量数据（千万级行）
* 多机组多风场数据分布不同

📌 处理策略

| 关键点  | 具体方案                           |
| ---- | ------------------------------ |
| 训练效率 | ✔ 顺序式联邦训练（逐机组训练并聚合）            |
| 噪声平滑 | ✔ 小窗口均值滤波                      |
| 分布差异 | ✔ 风场编码 / 机组 embedding          |
| 数据分段 | ✔ chunk-based streaming loader |
| 通用性  | ✔ window 参数可配置                 |

> 🧠 **顺序式联邦学习**
> 不是分布式，而是按设备逐个训练后聚合，避免设备间数据泄露，提高泛化能力并降低显存压力。

---

### Task2：水电入库流量预测（小时级、物理滞后、长依赖）

📌 特点：

* 3 小时分辨率
* 多源数据：降雨、预报、环境观测
* 滞后效应强
* 非均匀采样

📌 处理策略

| 关键点    | 具体方案                                               |
| ------ | -------------------------------------------------- |
| 滞后关系   | ✔ Shift-based feature engineering (+3h, +6h, +12h) |
| 多源异构数据 | ✔ 时间戳对齐 + 多模态拼接                                    |
| 缺失值    | ✔ Prophet 分解 & 滑动均值填补                              |
| 长期预测   | ✔ 增加 Trend 分量输出权重                                  |
| 可解释性   | ✔ 显示降雨 → 流量贡献曲线                                    |

---

### Task3：物料需求预测（极端稀疏、小样本）

📌 特点

* 最高稀疏（很多物料只有 <10 条记录）
* 缺失值不是异常，而是数据本身结构
* 类别特征多（物料类型、品类、品牌）
* 完整时间序列是离散月度的

📌 处理策略

| 关键点    | 具体方案                                |
| ------ | ----------------------------------- |
| 缺失补全   | ✔ B-Spline / periodic interpolation |
| 稀疏序列   | ✔ 周期展开 + zero padding               |
| 类别特征   | ✔ One-hot / target encoding         |
| 时间粒度统一 | ✔ 月级 resampling                     |
| 小样本泛化  | ✔ 强趋势权重 / 共享季节性参数                   |

> 💡 **B-Spline 插值**
> 优于线性插值，因为能保证平滑性与一阶连续性，特别适合库存/需求曲线。

---

## 6.5 🔧 模型结构与工程实现（核心图）

```
┌───────────────────────┐
│ Raw Data (3 tasks)    │
└─────────┬─────────────┘
          ↓
┌───────────────────────┐
│ Preprocessing + Align │ → resample / interpolate / encode
└─────────┬─────────────┘
          ↓
┌───────────────────────┐
│ Sliding Window Loader │ → 统一 L/H/d
└─────────┬─────────────┘
          ↓
┌───────────────────────┐
│ Neural Prophetic DLinear│ → trend + season + holiday + residual
└─────────┬─────────────┘
          ↓
┌───────────────────────┐
│ Inference + Export CSV│
└───────────────────────┘
```

---

## 6.6 🧩 整体方案优势总结（答辩可用）

### ✨ 技术亮点

* ✔ 首次将 Prophet 分解思想神经网络化用于工业时序
* ✔ 统一框架适配三种极端不同任务
* ✔ 用轻量模型达到可替代大模型效果
* ✔ 适合个人参赛 / 中小企业 / 无 GPU 场景
* ✔ 完全可解释
* ✔ 完全可复现（Docker）
* ✔ 可拓展为混合模型（Transformer / Diffusion 可插拔）

---

## 🔚 小结

> ❌ 我们不是在“避免使用大模型”
> ✔ 我们是在“用更适合工业场景的方式实现大模型应该做到的事”

---
## 7. 赛题总结与理解重点

✔ 三个任务差异巨大  
✔ 比赛重点不是预测分高，而是通用方法的设计  
✔ 需要从工程、算法、落地性全方位理解问题  
✔ 统一模型 ≠ 一个 checkpoint  
✔ 统一模型 = 统一范式 + 统一结构 + 统一 pipeline

---


