# 🧠 赛题解析与统一问题抽象  
**Industrial Multi-Scenario Forecasting — Problem Understanding**

本仓库对应比赛为：

> **第八届 数境杯 · 大模型工业多重场景挑战赛**
> 目标：使用一个通用模型完成三个完全不同的时间序列预测任务

---

## 1. 赛题目标：从“多模型”走向“通用模型”

### 传统范式
> 一个任务 → 一个模型 → 一个 pipeline

缺点：
❌ 无法复用  
❌ 每个任务重新调参  
❌ 扩展到新场景成本极高  
❌ 模型对工业落地不友好

### 本赛题范式要求
> 一个模型 → 多个任务 → 多种数据分布

目标是实现：
✔ 跨领域泛化  
✔ 统一数据接口  
✔ 无需重新设计模型结构  
✔ 具备可解释与工业可复现性  

换言之，比赛考察的不是 “你能不能调出一个高分模型”  
而是 **你能不能设计一个可扩展、可复现、可推广的系统**

---
## 2. 赛题解析与多场景差异分析

本次比赛要求选手使用 **同一个模型框架** 解决三个工业场景的预测任务。这三个场景不是简单变量替换，而是涵盖了**时间尺度、数据分布、稀疏程度、场景性质完全不同**的预测问题。

---

### 2.1 三个子赛题概述与核心挑战对比

| 赛题 | 场景 | 预测目标 | 时间粒度 | 特点与难点 |
|------|------|----------|-----------|-------------|
| Task 1 | 风电场 | 未来 10 分钟风速/风向（每 30 秒一次，共 20 步） | 30秒 | 高频序列、连续采样、强波动、机组差异大、数据规模大 |
| Task 2 | 水库入库 | 未来 7天入库流量（每 3 小时一次，共 56 步） | 3小时 | 存在物理滞后、降雨输入、气象驱动、长序列依赖、间断时间 |
| Task 3 | 离散制造 | 未来 1-3 个月物料需求预测（每月一次） | 月级 | 极端稀疏、nan密集、冷启动、需求不规律、数据量极小 |

---

### 2.2 为什么它们难以统一？
从时间序列的角度来看，本题最大的难点不是建模，而是 —— **数据结构完全不同**。

#### 📌 1. 时间尺度不一致
- Task1: 秒级（30s）
- Task2: 小时级（3h）
- Task3: 月级

这意味着：
> 不能简单共享采样窗口、序列长度、输入结构  
> 相当于三种不同的“时间世界”

#### 📌 2. 数据规模差异巨大
| 任务 | 样本规模 |
|------|---------|
| Task1 | 25台×2场×2年×30s → 数千万行 |
| Task2 | 4年×(每3小时) → ~12000行 |
| Task3 | 3年×(每月) → 36行（部分物料甚至不足10条） |

模型必须同时处理：
✔ big-data case (Task 1)  
✔ small-data case (Task 3)  
→ 这是大多数 deep learning / transformer 直接崩溃的场景

#### 📌 3. 数据稀疏性差异极大
Task1：连续传感器数据，无缺失（或可插值）  
Task2：存在间断、非均匀采样、缺失值  
Task3：天生稀疏，缺失是数据本身属性（不是异常）

> **这不仅仅是缺失值问题，而是数据生成机制不同**

#### 📌 4. 预测任务本质不同
| 任务 | 类型 |
|------|------|
| Task1 | 超短期预测（nowcasting） |
| Task2 | 水文时间序列（物理驱动） |
| Task3 | 离散业务时间序列（业务驱动） |

因此，三者不是“多任务”，而是三种完全不同的时间序列预测类型：

- **任务1像天气预报**
- **任务2像河流流域水量模型**
- **任务3更像销售预测问题**

---

### 2.3 总结：为什么这是一道真正的“通用建模”难题？

本赛题本质考察的是 ——  
✔ 对时序问题本质的抽象能力  
✔ 设计统一建模方法的理论基础  
✔ 面对三种极端不同数据集时，如何做到 **共享而不简单拼接**

因此，
**最难的不是模型怎么训练，而是如何构建一个合理的统一范式**

---

## 3. 比赛规则核心理解与影响

### ✔ 必须为“通用模型”
不是：
❌ 分别训练3个模型  
❌ 3个Notebook拼一起  
❌ 3个特征工程 pipeline

而应该是：
✔ 统一数据格式  
✔ 统一输入输出结构  
✔ 统一建模框架  
✔ 可以通用地支持任意任务

**只要是同一个模型框架 + 通用范式 = 合格**

甚至只要：
```

统一数据处理 + XGBoost

```
也完全符合规则（事实上，绝大多数队伍是这么做的）

---

### ✔ 不要求参数共享 / 多任务训练
这说明评委不在乎你是不是多任务 joint training  
而在乎你是否理解“通用性”的设计

---

## 4. 问题抽象：如何把三个任务统一成一个数学形式？

虽然看起来不同，但它们共享一个核心结构：

> 输入：过去 L 步的时间序列  
> 输出：未来 H 步预测值

统一为自回归滑动窗口格式：

<img width="700px" src="https://latex.codecogs.com/svg.image?X\in\mathbb{R}^{L\times&space;d},\quad&space;y\in\mathbb{R}^{H}">

只需修改：
- L（历史长度）
- H（预测长度）
- d（特征维度）
即可支持所有场景

> 核心思想：**用数据范式统一，而不是用模型硬套**

---
## 5. 本方案思路
我们的项目挑战性在于，需要用一个通用模型同时解决三个横跨不同行业的工业级子赛题：高频的风电场风况预测、中长期的水电站入库流量预测，以及高度稀疏的离散制造物料需求预测。我们的核心贡献是，在资源极其有限的情况下，设计了一个高效且高度通用的解决方案。
### 5.1 赛题分析
首先进行赛题分析，我们通过简单的预处理之后可视化了一些赛题数据。发现虽然这三个场景各不相同，但它们的时序数据都呈现出显著的共性特征：强噪声、多源异构、高波动性和非平稳性。面对这些挑战，我们迅速确定 ARIMA、Prophet 等传统统计模型不再适用。它们的核心缺陷在于：线性假设无法捕捉风电突变和水文径流的复杂非线性；建模维度受限，难以高效融合多个气象和业务特征；同时，对于物料需求中高度的稀疏性和间歇性也束手无策。因此，我们的起点是：必须采用深度学习算法来捕捉数据中复杂的非线性依赖关系。

在确定使用深度学习后，我们面临两个关键挑战：首先是场景多样性： 如何用一个模型统一处理 30 秒分辨率的超短期预测和 7 日的中长期预测？其次是资源约束（关键）： 本项目为个人独立参赛，我们仅能使用 Kaggle Notebook 和 Google Colab 等免费计算资源。这意味着我们无法进行大规模的分布式训练，无法长期占用 GPU，且模型的推理速度必须极快。因此，我们的目标非常明确：设计一个轻量级、高复现性，且在时序本质上具备通用性的预测框架，它必须比主流的 Transformer 更加高效。

竞赛明确鼓励使用通用大模型的思路进行建模。为了响应这一要求，我们首先尝试了如 TIMER-XL 这类长文本 Transformer 基线。然而，实证结果表明，这类模型在我们的工业级数据集上存在两个主要问题：首先是初始效果不佳： 原始的 Transformer 模型在我们的强噪声、小样本数据上，泛化能力并不理想。其次是资源与时间瓶颈： 无论是直接使用基线还是尝试指令微调，其高昂的训练成本和长时间的 GPU 占用，都远远超出了我们免费计算资源所能承受的范围。因此，我们决定进行学术转向，质疑这一路线的合理性。
### 5.2 赛题思路
我们放弃了 Transformer/LLM 的路径，是基于扎实的学术批判。我们引用了 **Christoph Bergmeir 教授在 NeurIPS 2024 上的主题演讲《Foundational limitations of foundational forecasting models》**中的核心观点：‘全局模型理论不适用于基础预测模型。’ Bergmeir 教授指出，目前许多时序 Transformer 模型缺乏严格的评估基准，其在特定数据集上的优势并不具备通用性。这一观点与我们的核心哲学不谋而合：任何时间序列的通用本质，在于其可分解的‘趋势’（Trend）和‘周期性’（Seasonality），而非复杂的非线性依赖。盲目堆砌大模型规模，并不能解决时序预测的核心挑战。”

“基于对时序本质的理解和对大模型的审慎态度，我们最终选择了AAAI23年的论文 **DLinear（LTSF-Linear、Zeng, A., Chen, M., Zhang, L., & Xu, Q. (2022). Are Transformers Effective for Time Series Forecasting? arXiv preprint arXiv:2205.13504v3.）**作为统一框架，并将其作为我们创新性的体现。我们引用 2023 年AAAI的论文，该研究证明了在有效分解序列后，一个简单的单层线性模型在长期预测基准上表现显著优于所有复杂的 Transformer 模型。这背后的核心原因论文作者表示是：Transformer 的核心机制 —— 自注意力是 “置换不变的”（对序列顺序不敏感），尽管通过位置编码等方式保留部分顺序信息，但其本质仍会导致时间信息丢失；而时间序列预测的核心是捕捉连续数据点的时间关系，顺序至关重要。此外，现有 Transformer-based LTSF 方法的性能提升可能源于其采用的 “直接多步（DMS）预测策略”，而非模型本身，因为它们对比的基线多是存在误差累积的 “迭代多步（IMS）预测”。DLinear 的优势在于：它将计算资源聚焦于高效的分解，而非复杂的非线性捕捉。这不仅解决了我们的算力限制问题，同时也提供了一个理论上更稳健、更符合时序特性的解决方案。

---

# ✨ 6. 技术解题路线（核心技术方案）

本节是本项目最核心的部分，将说明：

1. 我们如何通过统一范式处理三种极端不同的任务
2. 为什么选择 DLinear 而不是 Transformer
3. 如何将 Prophet 思想神经网络化进行增强
4. 针对三类赛题的自适应策略（重点）
5. 全部设计如何保证可扩展、可解释、可复现

---

## 6.1 🎯 总体策略对照表（核心思想一图总结）

| 关键挑战          | 常规失败方案            | 我们的策略                 |
| ------------- | ----------------- | --------------------- |
| 数据跨度差异极大      | 3 套独立模型           | 📌统一滑动窗口范式            |
| 小样本 + 缺失 + 噪声 | 手工填补 / 不处理        | 📌序列分解 + 插值策略         |
| 资源极度受限        | Transformer / LLM | 📌DLinear + CPU训练兼容   |
| 工业可解释性        | 黑盒深度模型            | 📌趋势-季节分解，高可解释        |
| 复现难           | Notebook + 复杂依赖   | 📌Docker 化，单脚本运行      |
| 通用性考核         | “套3个模型”假通用        | 📌同架构、同 pipeline、配置驱动 |

---

## 6.2 🧠 为什么选择 DLinear？（设计哲学）

DLinear 的核心思想：

> 用 **时间序列分解（Trend + Seasonal） + 线性层** 替代 Attention

它的结构像这样：

```
x ---> decomposition ---> [trend] ---> linear --> y_trend
                \-----> [season] --> linear --> y_season
y = y_trend + y_season
```

### 关键优势

✔ O(T) 复杂度，比 Transformer 更轻
✔ 支持小数据，不容易过拟合
✔ CPU/GPU 都能跑，Colab免费资源可复现
✔ 原生可解释，可视化趋势 & 周期成分
✔ 多赛题统一架构仍能保持性能

---

## 6.3 📌 DLinear ≈ Neural Prophet：我们做了进一步增强

原始 DLinear：

```
y = Linear(Trend(x)) + Linear(Season(x))
```

而 Prophet 的分解思想是：

```
y = Trend + Season + Holiday + Residual
```

我们将 Prophet 的思想 **神经网络化**，提出改进版本：

### 🔬 神经分解模型（我们的方法）

```
y = LT(Trend(x)) + LS(Season(x)) + LH(Holiday(x)) + LR(Residual(x))
```

其中：

* `LT` 捕捉趋势缓慢变化
* `LS` 捕捉周期波动（季节性）
* `LH` 注入节假日/业务事件（外生变量）
* `LR` 捕捉残差非线性成分

### 🌟 收益

| 指标    | 原始 DLinear | 我们改进版 |
| ----- | ---------- | ----- |
| 可解释性  | ✔          | ✔✔✔   |
| 小样本表现 | 中          | 高     |
| 长期预测  | 稳定         | 更稳    |
| 工业可用性 | ✔          | ✔✔    |

---

## 6.4 📍 三场景适配策略

### Task1：风电风况预测（秒级高频 / 数据量极大）

📌 特点：

* 30s 分辨率
* 巨量数据（千万级行）
* 多机组多风场数据分布不同

📌 处理策略

| 关键点  | 具体方案                           |
| ---- | ------------------------------ |
| 训练效率 | ✔ 顺序式联邦训练（逐机组训练并聚合）            |
| 噪声平滑 | ✔ 小窗口均值滤波                      |
| 分布差异 | ✔ 风场编码 / 机组 embedding          |
| 数据分段 | ✔ chunk-based streaming loader |
| 通用性  | ✔ window 参数可配置                 |

> 🧠 **顺序式联邦学习**
> 不是分布式，而是按设备逐个训练后聚合，避免设备间数据泄露，提高泛化能力并降低显存压力。

---

**🌀 ：顺序联邦学习在风电预测中的应用**

在处理 Task 1（风电场）数据时，我们面临一个严峻的挑战：**数据规模极其庞大**。单个风电场数年的秒级传感器数据就可能达到数千万甚至上亿条记录。直接将所有数据加载到内存中进行模型训练，不仅对硬件资源（内存、显存）提出了极高要求，还会导致训练过程极其缓慢，难以进行高效的模型迭代和调优。

为了解决这一问题，我们创新性地引入了**顺序联邦学习（Sequential Federated Learning, SFL）**的范式。

**1. 什么是顺序联邦学习 (Sequential Federated Learning)?**

传统的联邦学习（Federated Learning, FL）通常涉及多个**分布式的客户端**（例如，不同的医院、银行分行），每个客户端都持有自己的私有数据。中央服务器协调这些客户端，在不交换原始数据的前提下，共同训练一个全局模型。

**顺序联邦学习（SFL）**是联邦学习的一种变体，它特别适用于**数据无法或不便在同一时间点集中处理**的场景。其核心思想是：

1.  **数据分片（Data Sharding）**：将海量的中心化数据（或逻辑上分散的数据）按照某种规则（如时间、用户、设备）切分成多个独立的数据分片（Shard）。每个分片可以看作是一个“虚拟客户端”。
2.  **顺序训练（Sequential Training）**：
    a.  从第一个数据分片（虚拟客户端）加载数据。
    b.  使用该分片的数据对当前的全局模型进行局部训练（或微调）。
    c.  更新全局模型的参数。
    d.  丢弃当前分片的数据，释放内存。
    e.  加载下一个数据分片，重复步骤 b-d，直到所有分片都训练完毕。
3.  **全局模型聚合（Global Model Aggregation）**：在SFL中，模型聚合过程是**增量式**的。每训练完一个分片，就用其更新后的参数直接更新全局模型，而不是像传统FL那样等待所有客户端训练完毕后再进行一次集中式的聚合。

** 2. 我们在风电任务中的具体实践

**问题**：Task 1 包含多个风电场、数十台风机，每台风机每30秒产生一条记录，数据量巨大。

**我们的SFL方案**：

1.  **数据分片策略**：我们选择**按风机和时间窗口**进行分片。
    *   **一级分片**：以每台风机为单位，将其数据独立出来。
    *   **二级分片**：在每台风机的数据内部，再按照时间顺序切分成固定长度的时间窗口（例如，1个月的数据为一个分片）。
    *   **结果**：我们得到了大量的、相对较小的、独立的数据分片。例如：`wind_farm_A_turbine_01_month_2023_01`、`wind_farm_A_turbine_01_month_2023_02`、...、`wind_farm_B_turbine_10_month_2023_12` 等。

2.  **模型训练流程**：
    *   **初始化**：在中央服务器（我们的训练脚本）上，初始化一个DLinear模型作为全局模型 `G`。
    *   **循环训练**：遍历所有的数据分片：
        a.  **加载分片**：从磁盘加载当前数据分片 `S_i` 到内存。
        b.  **局部训练**：将全局模型 `G` 的当前参数作为初始值，使用分片 `S_i` 的数据对模型进行几轮（例如1-5轮）的局部训练。
        c.  **更新全局模型**：训练结束后，将分片 `S_i` 上训练好的模型参数直接赋值给全局模型 `G`，完成一次模型更新。
        d.  **清理**：删除内存中的分片 `S_i` 数据，为下一个分片腾出空间。
    *   **最终模型**：当所有分片都训练完成后，最终的全局模型 `G` 就融合了所有风机、所有时间段的数据特征。

    ```python
    # 伪代码示意
    global_model = DLinearModel() # 初始化全局模型
    all_shards = generate_all_data_shards() # 生成所有数据分片的路径列表

    for shard_path in all_shards:
        print(f"Training on shard: {shard_path}")
        
        # 1. 加载当前分片数据
        shard_data = load_data(shard_path)
        
        # 2. 使用当前分片数据训练全局模型
        # 这里的 train_on_shard 会用 shard_data 对 global_model 进行训练/微调
        train_on_shard(global_model, shard_data, epochs=2) 
        
        # 3. 模型已在内部更新，无需显式聚合
        # 4. 清理内存
        del shard_data 
        torch.cuda.empty_cache() 
    
    # 训练结束，global_model 即为最终模型
    save_model(global_model, "final_wind_model.pth")
    ```

* **3. 采用SFL带来的核心优势**

*   **解决内存瓶颈**：这是最直接的好处。我们不再需要一次性将TB级的数据加载到内存，而只需要处理MB或GB级别的数据分片，极大地降低了对硬件的要求。
*   **模拟分布式环境**：虽然我们的数据是中心化存储的，但SFL的训练方式模拟了一个分布式环境（每台风机是一个数据节点）。这使得我们的模型训练过程更贴近未来可能的工业部署场景。
*   **增强模型泛化性**：模型在训练过程中“见多识广”，依次学习了不同风机、不同时间段的特征，有助于防止模型过拟合到某一部分特定的数据，并能学习到更具普遍性的模式。
*   **提高训练效率**：虽然总的训练时间可能与集中式训练相当或略长（因为存在数据加载和模型保存的开销），但SFL将训练过程分解为多个小任务，可以更灵活地进行 checkpointing、中断后恢复，并且对硬件的瞬时压力小得多。

通过在风电预测任务中成功应用顺序联邦学习，我们不仅高效地处理了海量数据，还为模型赋予了更强的泛化能力和更贴近工业实际的训练模式，这充分体现了我们方案的创新性和工程实践能力。


### Task2：水电入库流量预测（小时级、物理滞后、长依赖）

📌 特点：

* 3 小时分辨率
* 多源数据：降雨、预报、环境观测
* 滞后效应强
* 非均匀采样

📌 处理策略

| 关键点    | 具体方案                                               |
| ------ | -------------------------------------------------- |
| 滞后关系   | ✔ Shift-based feature engineering (+3h, +6h, +12h) |
| 多源异构数据 | ✔ 时间戳对齐 + 多模态拼接                                    |
| 缺失值    | ✔ Prophet 分解 & 滑动均值填补                              |
| 长期预测   | ✔ 增加 Trend 分量输出权重                                  |
| 可解释性   | ✔ 显示降雨 → 流量贡献曲线                                    |

---

### Task3：物料需求预测（极端稀疏、小样本）

📌 特点

* 最高稀疏（很多物料只有 <10 条记录）
* 缺失值不是异常，而是数据本身结构
* 类别特征多（物料类型、品类、品牌）
* 完整时间序列是离散月度的

📌 处理策略

| 关键点    | 具体方案                                |
| ------ | ----------------------------------- |
| 缺失补全   | ✔ B-Spline / periodic interpolation |
| 稀疏序列   | ✔ 周期展开 + zero padding               |
| 类别特征   | ✔ One-hot / target encoding         |
| 时间粒度统一 | ✔ 月级 resampling                     |
| 小样本泛化  | ✔ 强趋势权重 / 共享季节性参数                   |

> 💡 **B-Spline 插值**
> 优于线性插值，因为能保证平滑性与一阶连续性，特别适合库存/需求曲线。

---

## 6.5 🔧 模型结构与工程实现（核心图）

```
┌───────────────────────┐
│ Raw Data (3 tasks)    │
└─────────┬─────────────┘
          ↓
┌───────────────────────┐
│ Preprocessing + Align │ → resample / interpolate / encode
└─────────┬─────────────┘
          ↓
┌───────────────────────┐
│ Sliding Window Loader │ → 统一 L/H/d
└─────────┬─────────────┘
          ↓
┌───────────────────────┐
│ Neural Prophetic DLinear│ → trend + season + holiday + residual
└─────────┬─────────────┘
          ↓
┌───────────────────────┐
│ Inference + Export CSV│
└───────────────────────┘
```

---

## 6.6 🧩 整体方案优势总结

### ✨ 技术亮点

* ✔ 首次将 Prophet 分解思想神经网络化用于工业时序
* ✔ 统一框架适配三种极端不同任务
* ✔ 用轻量模型达到可替代大模型效果
* ✔ 适合个人参赛 / 中小企业 / 无 GPU 场景
* ✔ 完全可解释
* ✔ 完全可复现（Docker）
* ✔ 可拓展为混合模型（Transformer / Diffusion 可插拔）

---

## 🔚 小结

> ❌ 我们不是在“避免使用大模型”
> ✔ 我们是在“用更适合工业场景的方式实现大模型应该做到的事”

---
## 7. 赛题总结与理解重点

✔ 三个任务差异巨大  
✔ 比赛重点不是预测分高，而是通用方法的设计  
✔ 需要从工程、算法、落地性全方位理解问题  
✔ 统一模型 ≠ 一个 checkpoint  
✔ 统一模型 = 统一范式 + 统一结构 + 统一 pipeline

---


